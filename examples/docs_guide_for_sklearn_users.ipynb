{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lale: Language for Automated Learning Exploration\n",
    "\n",
    "### Git Repo: https://github.com/IBM/lale\n",
    "\n",
    "\n",
    "This tutorial is meant to be used as a quick start guide for Lale by data scientists familiar with the scikit-learn library.\n",
    "\n",
    "\n",
    "## Value Proposition\n",
    "\n",
    "The **target user** of Lale is the working data scientist. The\n",
    "**scope** of Lale includes machine learning (both deep learning and\n",
    "non-DL) and data preparation. The **value** of Lale encompasses:\n",
    "\n",
    "<img src=\"img/2019-0717-four-values.jpg\" style=\"width:100%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "\n",
    "Please follow the installation instructions at https://github.com/IBM/lale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminology\n",
    "\n",
    "* Operator: An operator is an implementation of a machine learning algorithm. The term operator can be used to indicate a transformer or an estimator from scikit-learn or any other implementation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple example of classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The example shows how to use a dataset from scikit-learn for classification. Lale provides easy access to some standard datasets in its lale.datasets package. In theory, user can use any dataset appropriate for a task as long as it is compatible with the algorithms operating on those. For structured datasets, most common formats supported by Lale are Numpy ndarrays and Pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "X, y = sklearn.datasets.load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers\n",
    "\n",
    "Lale provides wrappers to many scikit-learn algorithms. All these wrappers can be accessed from lale.lib.sklearn with the same name as the original scikit-learn class name. For example, \"from lale.lib.sklearn import LogisticRegression\". Jump to the FAQ section below if such an import statement for your favorite algorithm fails.\n",
    "\n",
    "The example below illustrates use of LogisticRegression from Lale with the scikit-learn compatible fit and predict apis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lale.lib.sklearn import LogisticRegression\n",
    "clf = LogisticRegression(solver='liblinear', C=0.9)\n",
    "trained_clf = clf.fit(X_train, y_train)\n",
    "predictions = trained_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 97.4%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('accuracy {:.1%}'.format(accuracy_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Documentation\n",
    "\n",
    "Below are some examples of interactive documentation provided by Lale on the operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'liblinear', 'penalty': 'l2', 'dual': False, 'C': 1.0, 'tol': 0.0001, 'fit_intercept': True, 'intercept_scaling': 1.0, 'class_weight': None, 'random_state': None, 'max_iter': 100, 'multi_class': 'auto', 'verbose': 0, 'warm_start': False, 'n_jobs': None}\n"
     ]
    }
   ],
   "source": [
    "print(LogisticRegression.hyperparam_defaults())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Inverse regularization strength. Smaller values specify stronger regularization.',\n",
       " 'type': 'number',\n",
       " 'distribution': 'loguniform',\n",
       " 'minimum': 0.0,\n",
       " 'exclusiveMinimum': True,\n",
       " 'default': 1.0,\n",
       " 'minimumForOptimizer': 0.03125,\n",
       " 'maximumForOptimizer': 32768}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression.hyperparam_schema('C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "Lale allows data scientists to represent combinations of operators as pipelines. Unlike scikit-learn pipelines, there are no restrictions on Lale pipelines in the sequence of transformers and estimators or the shape of the pipeline (any directed acyclic graph is accommodated). Lale pipeline is a lot more flexible and provides advanced features which will be discussed in other advanced Lale tutorials.\n",
    "\n",
    "Lale pipelines can be created using `make_pipeline` similar to scikit-learn. There are also some composition operators listed below which can be used to create complex pipelines with easy syntax.\n",
    "\n",
    "| Symbol | Name | Description  | Sklearn feature |\n",
    "| ------ | ---- | ------------ | --------------- |\n",
    "| >>     | pipe | Feed to next | `make_pipeline` |\n",
    "| &      | and  | Run both     | `make_union`, includes concat |\n",
    "| &#x7c; | or   | Choose one   | (missing) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example below shows how to combine feature selection/pre-processing and classification in a pipeline and use it to train and predict on the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lale.lib.sklearn import StandardScaler,  PCA\n",
    "from lale.lib.xgboost import XGBClassifier\n",
    "from lale.operators import make_pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lale_pipeline = StandardScaler() >> PCA(n_components = 3) >> XGBClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lale_pipeline = make_pipeline(StandardScaler(), PCA(n_components = 3), XGBClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize a Lale pipeline using graphviz as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"386pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 386.27 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-40 382.2716,-40 382.2716,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<g id=\"a_node1\"><a xlink:title=\"StandardScaler\">\n",
       "<ellipse fill=\"#b0e2ff\" stroke=\"#000000\" cx=\"63.6383\" cy=\"-18\" rx=\"63.7769\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63.6383\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">StandardScaler</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<g id=\"a_node2\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\" xlink:title=\"PCA(n_components=3)\">\n",
       "<ellipse fill=\"#b0e2ff\" stroke=\"#000000\" cx=\"190.5867\" cy=\"-18\" rx=\"27.1216\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"190.5867\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">PCA</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M127.4844,-18C136.2423,-18 144.9908,-18 153.0629,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"153.2288,-21.5001 163.2288,-18 153.2288,-14.5001 153.2288,-21.5001\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<g id=\"a_node3\"><a xlink:title=\"XGBClassifier\">\n",
       "<ellipse fill=\"#b0e2ff\" stroke=\"#000000\" cx=\"316.0842\" cy=\"-18\" rx=\"62.3754\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"316.0842\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">XGBClassifier</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M218.1277,-18C225.8339,-18 234.5877,-18 243.6166,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"243.8863,-21.5001 253.8862,-18 243.8862,-14.5001 243.8863,-21.5001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x120509ef0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lale.helpers import to_graphviz\n",
    "to_graphviz(lale_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_pipeline = lale_pipeline.fit(X_train, y_train)\n",
    "predictions = trained_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined algorithm selection and hyper-parameter tuning (CASH)\n",
    "\n",
    "Lale provides out-of-the-box support for 3 popular optimizers (grid search, Hyperopt, SMAC) for combined algorithm selection and hyper-parameter tuning. Users have to choose the algorithms and pipeline structure they want to consider, and Lale can select the best performing algorithms and hyper-parameter combination from those. If users would like some fixed values of hyper-parameters, they can create the operator objects with those values and the tuning step won't tune that hyper-parameter. There are more advanced ways to over-ride the search spaces, but we defer that discussion to Lale advanced tutorials.\n",
    "\n",
    "The examples below show a typical CASH usage with Lale for our classification example. We show use of Hyperopt and grid search in the examples. SMAC is another optimizer supported by Lale, but we omit it for this tutorial since installation of SMAC is non trivial for some platforms.\n",
    "\n",
    "Note that the example below is using the `|` operator to indicate the choice of operators. And `NoOp` here means `No Operation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lale.lib.lale import NoOp\n",
    "from lale.lib.sklearn import MinMaxScaler, GradientBoostingClassifier, KNeighborsClassifier, RandomForestClassifier, \\\n",
    "ExtraTreesClassifier\n",
    "lale_pipeline = (NoOp() | MinMaxScaler() | StandardScaler()) >> \\\n",
    "                (NoOp() | PCA()) >> \\\n",
    "                (GradientBoostingClassifier(loss='deviance') | KNeighborsClassifier() | RandomForestClassifier() | ExtraTreesClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HyperoptClassifier used below is a Lale operator defined to use Hyperopt for classification. There is lale.lib.lale.HyperoptRegressor for regression. Users can use Hyperopt for other tasks by following those examples and a detailed discussion of those can be found in Lale advanced tutorials.\n",
    "\n",
    "The HyperoptClassifier takes the lale pipeline as input and has a parameter `max_evals` to refer to the number of iterations of pipeline tuning. For example, `max_evals = 10` would consider 10 different configurations of the given pipeline and output the best of those. Note that it is using `accuracy` as a metric while choosing the best pipeline.\n",
    "\n",
    "Lale helps to minimize the number of invalid runs out of those `max_evals` number of iterations, but there could still be some such runs. HyperoptClassifier will output a warning in such cases, set the accuracy to zero corresponding to that run and continue to the next run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lale.lib.lale.hyperopt_classifier import HyperoptClassifier\n",
    "optimizer = HyperoptClassifier(model=lale_pipeline, max_evals=10)\n",
    "trained = optimizer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the `trained` pipeline output shows that Hyperopt picked PCA followed by KNeighborsClassifier for this dataset after 10 iterations of tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"372pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 371.56 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-40 367.5556,-40 367.5556,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<g id=\"a_node1\"><a xlink:href=\"https://github.com/IBM/lale\" xlink:title=\"NoOp\">\n",
       "<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"31.7232\" cy=\"-18\" rx=\"31.948\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"31.7232\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">NoOp</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<g id=\"a_node2\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\" xlink:title=\"PCA\">\n",
       "<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"126.7566\" cy=\"-18\" rx=\"27.1216\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"126.7566\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">PCA</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M63.6323,-18C71.8361,-18 80.7381,-18 89.199,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"89.2242,-21.5001 99.2241,-18 89.2241,-14.5001 89.2242,-21.5001\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<g id=\"a_node3\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\" xlink:title=\"KNeighborsClassifier(algorithm=&#39;ball_tree&#39;, n_neighbors=22, p=1, weights=&#39;distance&#39;)\">\n",
       "<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"276.8111\" cy=\"-18\" rx=\"86.9896\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"276.8111\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">KNeighborsClassifier</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M154.2789,-18C161.8593,-18 170.5387,-18 179.7005,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"179.8021,-21.5001 189.8021,-18 179.8021,-14.5001 179.8021,-21.5001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x1230d2780>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_graphviz(trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the best hyper-parameter values that the tuning selected as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': 'lale.operators.TrainedPipeline',\n",
       " 'state': 'trained',\n",
       " 'edges': [[0, 1], [1, 2]],\n",
       " 'steps': [{'class': 'lale.lib.lale.no_op.NoOpImpl',\n",
       "   'state': 'trained',\n",
       "   'operator': 'NoOp',\n",
       "   'documentation_url': 'https://github.com/IBM/lale',\n",
       "   'hyperparams': {}},\n",
       "  {'class': 'lale.lib.sklearn.pca.PCAImpl',\n",
       "   'state': 'trained',\n",
       "   'operator': 'PCA',\n",
       "   'documentation_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html',\n",
       "   'hyperparams': {}},\n",
       "  {'class': 'lale.lib.sklearn.k_neighbors_classifier.KNeighborsClassifierImpl',\n",
       "   'state': 'trained',\n",
       "   'operator': 'KNeighborsClassifier',\n",
       "   'documentation_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html',\n",
       "   'hyperparams': {'algorithm': 'ball_tree',\n",
       "    'n_neighbors': 22,\n",
       "    'p': 1,\n",
       "    'weights': 'distance'}}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lale also generates the input parameter grid for GridSearchCV automatically and has a wrapper for scikit-learn's GridSearchCV. It can be used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lale.search.GridSearchCV import LaleGridSearchCV\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "\n",
    "grid_search = LaleGridSearchCV(lale_pipeline, lale_num_samples=1, lale_num_grids=1, cv=2,\n",
    "                scoring=make_scorer(accuracy_score))\n",
    "trained = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example illustrates union of operators followed by `ConcatFeatures` which concats their output. The combination works similar to `FeatureUnion` from scikit-learn. Here, the output of PCA and Nystroem is concatenated together and passed to the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"785pt\" height=\"98pt\"\n",
       " viewBox=\"0.00 0.00 784.95 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-94 780.9451,-94 780.9451,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<g id=\"a_node1\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\" xlink:title=\"MinMaxScaler(feature_range=(0, 1))\">\n",
       "<ellipse fill=\"#b0e2ff\" stroke=\"#000000\" cx=\"63.1547\" cy=\"-45\" rx=\"63.3097\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63.1547\" y=\"-40.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">MinMaxScaler</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<g id=\"a_node2\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\" xlink:title=\"PCA(n_components=3)\">\n",
       "<ellipse fill=\"#b0e2ff\" stroke=\"#000000\" cx=\"207.2934\" cy=\"-72\" rx=\"27.1216\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"207.2934\" y=\"-67.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">PCA</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M116.0082,-54.9005C134.2392,-58.3155 154.24,-62.0621 170.8612,-65.1755\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"170.2541,-68.6226 180.7276,-67.0237 171.543,-61.7423 170.2541,-68.6226\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<g id=\"a_node3\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.kernel_approximation.Nystroem.html\" xlink:title=\"Nystroem(n_components=3)\">\n",
       "<ellipse fill=\"#b0e2ff\" stroke=\"#000000\" cx=\"207.2934\" cy=\"-18\" rx=\"44.9682\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"207.2934\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Nystroem</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M116.0082,-35.0995C129.0681,-32.6531 143.0363,-30.0366 156.0198,-27.6046\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"157.0003,-30.9818 166.185,-25.7004 155.7115,-24.1015 157.0003,-30.9818\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<g id=\"a_node4\"><a xlink:href=\"https://github.com/IBM/lale\" xlink:title=\"ConcatFeatures\">\n",
       "<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"353.3926\" cy=\"-45\" rx=\"65.2304\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"353.3926\" y=\"-40.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ConcatFeatures</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M233.7509,-67.1105C249.2262,-64.2506 269.4894,-60.5058 288.93,-56.9131\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"289.7941,-60.3127 298.9915,-55.0537 288.5219,-53.4293 289.7941,-60.3127\"/>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M248.379,-25.5929C261.0791,-27.9399 275.3849,-30.5837 289.2555,-33.1471\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"288.7798,-36.6184 299.2494,-34.994 290.0519,-29.7349 288.7798,-36.6184\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<g id=\"a_node5\"><a xlink:title=\"LogisticRegression | KNeighborsClassifier\">\n",
       "<ellipse fill=\"#7ec0ee\" stroke=\"#000000\" cx=\"615.7264\" cy=\"-45\" rx=\"161.4377\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"615.7264\" y=\"-40.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">LogisticRegression | KNeighborsClassifier</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M418.5762,-45C426.7349,-45 435.3541,-45 444.2471,-45\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"444.3941,-48.5001 454.3941,-45 444.3941,-41.5001 444.3941,-48.5001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x126659048>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lale.lib.lale import ConcatFeatures\n",
    "from lale.lib.lale import NoOp\n",
    "from lale.lib.sklearn import MinMaxScaler\n",
    "from lale.lib.sklearn import Nystroem\n",
    "\n",
    "def my_pipeline(scale=False, n_components=10, clf=LogisticRegression()):\n",
    "    scl = MinMaxScaler(feature_range=(0, 1)) if scale else NoOp\n",
    "    pca = PCA(n_components=n_components)\n",
    "    nys = Nystroem(n_components=n_components)\n",
    "    return scl >> (pca & nys) >> ConcatFeatures >> clf\n",
    "\n",
    "optimizable = my_pipeline(True, 3, LogisticRegression() | KNeighborsClassifier())\n",
    "to_graphviz(optimizable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you notice different colors in the nodes of the above graphviz visualization, this is an important feature of Lale, called lifecycle stages, more details can be found in Lale advanced tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other ML tasks\n",
    "\n",
    "The core Lale functionality demonstrated above works the same way for the tasks below. Also, the example above mostly demonstrates algorithms from scikit-learn, but Lale also has operators based on other frameworks including some deep learning implementations. Please slack **#lale-users** for more details or browse Lale git repository at **https://github.com/IBM/lale** for more information.\n",
    "\n",
    "* **Regression on tabular data**\n",
    "* **Sequence/time-series classification/regression**\n",
    "* **Text classification**\n",
    "* **Image classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAQ\n",
    "\n",
    "* **The algorithm I want to use is not present in Lale. Can I still use it?**\n",
    "\n",
    "    Some of the features of Lale can be used if the algorithm implementation follows a scikit-learn API of fit/predict or fit/transform. You can cast the operator into a Lale operator as follows:\n",
    "\n",
    "```python\n",
    "from lale.operators import make_operator\n",
    "\n",
    "lale_op = make_operator(non_lale_op)\n",
    "```\n",
    "\n",
    "* **I get an error when I instantiate an operator imported from Lale.**\n",
    "\n",
    "    Lale raises errors on invalid hyperparameter values or combinations. This ensures that the operators are used correctly. So don't be surprised if you get any errors when you initialize Lale operators with some hyperparameter values. Chances are that those hyperpameters or combinations of hyperparameters are invalid. If not, find us at **#lale-users** on slack."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
