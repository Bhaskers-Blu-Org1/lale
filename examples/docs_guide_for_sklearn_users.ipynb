{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lale: Language for Automated Learning Exploration\n",
    "\n",
    "### Git Repo: https://github.ibm.com/aimodels/lale\n",
    "\n",
    "\n",
    "This tutorial is meant to be used as a quick start guide for Lale by data scientists familiar with the scikit-learn library.\n",
    "\n",
    "\n",
    "## Value Proposition\n",
    "\n",
    "The **target user** of Lale is the working data scientist. The\n",
    "**scope** of Lale includes machine learning (both deep learning and\n",
    "non-DL) and data preparation. The **value** of Lale encompasses:\n",
    "\n",
    "<img src=\"img/2019-0717-four-values.jpg\" style=\"width:100%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "\n",
    "Please follow the installation instructions at https://github.ibm.com/aimodels/lale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminology\n",
    "\n",
    "* Operator: An operator is an implementation of a machine learning algorithm. The term operator can be used to indicate a transformer or an estimator from scikit-learn or any other implementation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple example of classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The example shows how to use a dataset from scikit-learn for classification. Lale provides easy access to some standard datasets in its lale.datasets package. In theory, user can use any dataset appropriate for a task as long as it is compatible with the algorithms operating on those. For structured datasets, most common formats supported by Lale are Numpy ndarrays and Pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "X, y = sklearn.datasets.load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers\n",
    "\n",
    "Lale provides wrappers to many scikit-learn algorithms. All these wrappers can be accessed from lale.lib.sklearn with the same name as the original scikit-learn class name. For example, \"from lale.lib.sklearn import LogisticRegression\". Jump to the FAQ section below if such an import statement for your favorite algorithm fails.\n",
    "\n",
    "The example below illustrates use of LogisticRegression from Lale with the scikit-learn compatible fit and predict apis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lale.lib.sklearn import LogisticRegression\n",
    "clf = LogisticRegression(solver='liblinear', C=0.9)\n",
    "trained_clf = clf.fit(X_train, y_train)\n",
    "predictions = trained_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 89.5%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('accuracy {:.1%}'.format(accuracy_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Documentation\n",
    "\n",
    "Below are some examples of interactive documentation provided by Lale on the operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'liblinear', 'penalty': 'l2', 'dual': False, 'C': 1.0, 'tol': 0.0001, 'fit_intercept': True, 'intercept_scaling': 1.0, 'class_weight': None, 'random_state': None, 'max_iter': 100, 'multi_class': 'auto', 'verbose': 0, 'warm_start': False, 'n_jobs': None}\n"
     ]
    }
   ],
   "source": [
    "print(LogisticRegression.hyperparam_defaults())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Inverse regularization strength. Smaller values specify stronger regularization.',\n",
       " 'type': 'number',\n",
       " 'distribution': 'loguniform',\n",
       " 'minimum': 0.0,\n",
       " 'exclusiveMinimum': True,\n",
       " 'default': 1.0,\n",
       " 'minimumForOptimizer': 0.03125,\n",
       " 'maximumForOptimizer': 32768}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression.hyperparam_schema('C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "Lale allows data scientists to represent combinations of operators as pipelines. Unlike scikit-learn pipelines, there are no restrictions on Lale pipelines in the sequence of transformers and estimators or the shape of the pipeline (any directed acyclic graph is accommodated). Lale pipeline is a lot more flexible and provides advanced features which will be discussed in other advanced Lale tutorials.\n",
    "\n",
    "Lale pipelines can be created using `make_pipeline` similar to scikit-learn. There are also some composition operators listed below which can be used to create complex pipelines with easy syntax.\n",
    "\n",
    "| Symbol | Name | Description  | Sklearn feature |\n",
    "| ------ | ---- | ------------ | --------------- |\n",
    "| >>     | pipe | Feed to next | `make_pipeline` |\n",
    "| &      | and  | Run both     | `make_union`, includes concat |\n",
    "| &#x7c; | or   | Choose one   | (missing) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example below shows how to combine feature selection/pre-processing and classification in a pipeline and use it to train and predict on the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lale.lib.sklearn import StandardScaler,  PCA\n",
    "from lale.lib.xgboost import XGBClassifier\n",
    "from lale.operators import make_pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lale_pipeline = StandardScaler() >> PCA(n_components = 3) >> XGBClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lale_pipeline = make_pipeline(StandardScaler(), PCA(n_components = 3), XGBClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize a Lale pipeline using graphviz as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"389pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 389.37 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-40 385.373,-40 385.373,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<g id=\"a_node1\"><a xlink:title=\"StandardScaler\">\n",
       "<ellipse fill=\"#b0e2ff\" stroke=\"black\" cx=\"63.6943\" cy=\"-18\" rx=\"63.8893\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63.6943\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">StandardScaler</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<g id=\"a_node2\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\" xlink:title=\"PCA(n_components=3)\">\n",
       "<ellipse fill=\"#b0e2ff\" stroke=\"black\" cx=\"191.336\" cy=\"-18\" rx=\"27.8951\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"191.336\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">PCA</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127.515,-18C136.303,-18 145.09,-18 153.189,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"153.383,-21.5001 163.383,-18 153.383,-14.5001 153.383,-21.5001\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\n",
       "<g id=\"a_node3\"><a xlink:title=\"XGBClassifier\">\n",
       "<ellipse fill=\"#b0e2ff\" stroke=\"black\" cx=\"318.328\" cy=\"-18\" rx=\"63.0888\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"318.328\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">XGBClassifier</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M219.458,-18C227.126,-18 235.854,-18 244.866,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"245.12,-21.5001 255.12,-18 245.12,-14.5001 245.12,-21.5001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f6551668780>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lale.helpers import to_graphviz\n",
    "to_graphviz(lale_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_pipeline = lale_pipeline.fit(X_train, y_train)\n",
    "predictions = trained_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined algorithm selection and hyper-parameter tuning (CASH)\n",
    "\n",
    "Lale provides out-of-the-box support for 3 popular optimizers (grid search, Hyperopt, SMAC) for combined algorithm selection and hyper-parameter tuning. Users have to choose the algorithms and pipeline structure they want to consider, and Lale can select the best performing algorithms and hyper-parameter combination from those. If users would like some fixed values of hyper-parameters, they can create the operator objects with those values and the tuning step won't tune that hyper-parameter. There are more advanced ways to over-ride the search spaces, but we defer that discussion to Lale advanced tutorials.\n",
    "\n",
    "The examples below show a typical CASH usage with Lale for our classification example. We show use of Hyperopt and grid search in the examples. SMAC is another optimizer supported by Lale, but we omit it for this tutorial since installation of SMAC is non trivial for some platforms.\n",
    "\n",
    "Note that the example below is using the `|` operator to indicate the choice of operators. And `NoOp` here means `No Operation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lale.lib.lale import NoOp\n",
    "from lale.lib.sklearn import MinMaxScaler, GradientBoostingClassifier, KNeighborsClassifier, RandomForestClassifier, \\\n",
    "ExtraTreesClassifier\n",
    "lale_pipeline = (NoOp() | MinMaxScaler() | StandardScaler()) >> \\\n",
    "                (NoOp() | PCA()) >> \\\n",
    "                (GradientBoostingClassifier(loss='deviance') | KNeighborsClassifier() | RandomForestClassifier() | ExtraTreesClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HyperoptClassifier used below is a Lale operator defined to use Hyperopt for classification. There is lale.lib.lale.HyperoptRegressor for regression. Users can use Hyperopt for other tasks by following those examples and a detailed discussion of those can be found in Lale advanced tutorials.\n",
    "\n",
    "The HyperoptClassifier takes the lale pipeline as input and has a parameter `max_evals` to refer to the number of iterations of pipeline tuning. For example, `max_evals = 10` would consider 10 different configurations of the given pipeline and output the best of those. Note that it is using `accuracy` as a metric while choosing the best pipeline.\n",
    "\n",
    "Lale helps to minimize the number of invalid runs out of those `max_evals` number of iterations, but there could still be some such runs. HyperoptClassifier will output a warning in such cases, set the accuracy to zero corresponding to that run and continue to the next run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:25<00:00,  3.03s/it, best loss: -0.9733333333333333]\n"
     ]
    }
   ],
   "source": [
    "from lale.lib.lale.hyperopt_classifier import HyperoptClassifier\n",
    "optimizer = HyperoptClassifier(model=lale_pipeline, max_evals=10)\n",
    "trained = optimizer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the `trained` pipeline output shows that Hyperopt picked PCA followed by KNeighborsClassifier for this dataset after 10 iterations of tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"375pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 375.07 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-40 371.074,-40 371.074,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<g id=\"a_node1\"><a xlink:href=\"https://github.ibm.com/aimodels/lale\" xlink:title=\"NoOp\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"32.4971\" cy=\"-18\" rx=\"32.4942\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"32.4971\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">NoOp</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<g id=\"a_node2\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\" xlink:title=\"PCA\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"128.942\" cy=\"-18\" rx=\"27.8951\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"128.942\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">PCA</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M65.2085,-18C73.4377,-18 82.3738,-18 90.8525,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"90.8896,-21.5001 100.89,-18 90.8895,-14.5001 90.8896,-21.5001\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\n",
       "<g id=\"a_node3\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\" xlink:title=\"KNeighborsClassifier(algorithm=&#39;ball_tree&#39;, n_neighbors=22, p=1, weights=&#39;distance&#39;)\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"279.982\" cy=\"-18\" rx=\"87.1846\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"279.982\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">KNeighborsClassifier</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M156.932,-18C164.571,-18 173.353,-18 182.63,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"182.861,-21.5001 192.861,-18 182.861,-14.5001 182.861,-21.5001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f653f173710>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_graphviz(trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the best hyper-parameter values that the tuning selected as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': 'lale.operators.TrainedPipeline',\n",
       " 'state': 'trained',\n",
       " 'edges': [[0, 1], [1, 2]],\n",
       " 'steps': [{'class': 'lale.lib.lale.no_op.NoOpImpl',\n",
       "   'state': 'trained',\n",
       "   'operator': 'NoOp',\n",
       "   'documentation_url': 'https://github.ibm.com/aimodels/lale',\n",
       "   'hyperparams': {}},\n",
       "  {'class': 'lale.lib.sklearn.pca.PCAImpl',\n",
       "   'state': 'trained',\n",
       "   'operator': 'PCA',\n",
       "   'documentation_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html',\n",
       "   'hyperparams': {}},\n",
       "  {'class': 'lale.lib.sklearn.k_neighbors_classifier.KNeighborsClassifierImpl',\n",
       "   'state': 'trained',\n",
       "   'operator': 'KNeighborsClassifier',\n",
       "   'documentation_url': 'https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html',\n",
       "   'hyperparams': {'algorithm': 'ball_tree',\n",
       "    'n_neighbors': 22,\n",
       "    'p': 1,\n",
       "    'weights': 'distance'}}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lale also generates the input parameter grid for GridSearchCV automatically and has a wrapper for scikit-learn's GridSearchCV. It can be used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lale.search.GridSearchCV import LaleGridSearchCV\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "\n",
    "grid_search = LaleGridSearchCV(lale_pipeline, lale_num_samples=1, lale_num_grids=1, cv=2,\n",
    "                scoring=make_scorer(accuracy_score))\n",
    "trained = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example illustrates union of operators followed by `ConcatFeatures` which concats their output. The combination works similar to `FeatureUnion` from scikit-learn. Here, the output of PCA and Nystroem is concatenated together and passed to the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"792pt\" height=\"98pt\"\n",
       " viewBox=\"0.00 0.00 791.94 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-94 787.94,-94 787.94,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<g id=\"a_node1\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\" xlink:title=\"MinMaxScaler(feature_range=(0, 1))\">\n",
       "<ellipse fill=\"#b0e2ff\" stroke=\"black\" cx=\"64.3443\" cy=\"-45\" rx=\"64.189\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"64.3443\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">MinMaxScaler</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<g id=\"a_node2\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\" xlink:title=\"PCA(n_components=3)\">\n",
       "<ellipse fill=\"#b0e2ff\" stroke=\"black\" cx=\"210.834\" cy=\"-72\" rx=\"27.8951\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"210.834\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">PCA</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M118.327,-54.9005C136.735,-58.3404 156.944,-62.1168 173.678,-65.2436\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"173.128,-68.7013 183.6,-67.0978 174.413,-61.8204 173.128,-68.7013\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\n",
       "<g id=\"a_node3\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.kernel_approximation.Nystroem.html\" xlink:title=\"Nystroem(n_components=3)\">\n",
       "<ellipse fill=\"#b0e2ff\" stroke=\"black\" cx=\"210.834\" cy=\"-18\" rx=\"46.2923\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"210.834\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Nystroem</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M118.327,-35.0995C131.418,-32.6531 145.421,-30.0366 158.436,-27.6046\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"159.439,-30.9778 168.626,-25.7004 158.153,-24.0969 159.439,-30.9778\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\n",
       "<g id=\"a_node4\"><a xlink:href=\"https://github.ibm.com/aimodels/lale\" xlink:title=\"ConcatFeatures\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"358.625\" cy=\"-45\" rx=\"65.7887\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"358.625\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">ConcatFeatures</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M237.899,-67.1729C253.523,-64.2793 274.126,-60.4637 293.828,-56.815\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"294.513,-60.2478 303.708,-54.9852 293.238,-53.3648 294.513,-60.2478\"/>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M252.833,-25.5929C265.574,-27.9525 279.935,-30.612 293.845,-33.1882\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"293.395,-36.6643 303.865,-35.0439 294.67,-29.7813 293.395,-36.6643\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\n",
       "<g id=\"a_node5\"><a xlink:title=\"LogisticRegression | KNeighborsClassifier\">\n",
       "<ellipse fill=\"#7ec0ee\" stroke=\"black\" cx=\"622.104\" cy=\"-45\" rx=\"161.671\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"622.104\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">LogisticRegression | KNeighborsClassifier</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M424.596,-45C432.673,-45 441.203,-45 450.004,-45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"450.045,-48.5001 460.045,-45 450.045,-41.5001 450.045,-48.5001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f653f08d0b8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lale.lib.lale import ConcatFeatures\n",
    "from lale.lib.lale import NoOp\n",
    "from lale.lib.sklearn import MinMaxScaler\n",
    "from lale.lib.sklearn import Nystroem\n",
    "\n",
    "def my_pipeline(scale=False, n_components=10, clf=LogisticRegression()):\n",
    "    scl = MinMaxScaler(feature_range=(0, 1)) if scale else NoOp\n",
    "    pca = PCA(n_components=n_components)\n",
    "    nys = Nystroem(n_components=n_components)\n",
    "    return scl >> (pca & nys) >> ConcatFeatures >> clf\n",
    "\n",
    "optimizable = my_pipeline(True, 3, LogisticRegression() | KNeighborsClassifier())\n",
    "to_graphviz(optimizable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you notice different colors in the nodes of the above graphviz visualization, this is an important feature of Lale, called lifecycle stages, more details can be found in Lale advanced tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other ML tasks\n",
    "\n",
    "The core Lale functionality demonstrated above works the same way for the tasks below. Also, the example above mostly demonstrates algorithms from scikit-learn, but Lale also has operators based on other frameworks including some deep learning implementations. Please slack **#lale-users** for more details or browse Lale git repository at **https://github.ibm.com/aimodels/lale** for more information.\n",
    "\n",
    "* **Regression on tabular data**\n",
    "* **Sequence/time-series classification/regression**\n",
    "* **Text classification**\n",
    "* **Image classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAQ\n",
    "\n",
    "* **The algorithm I want to use is not present in Lale. Can I still use it?**\n",
    "\n",
    "    Some of the features of Lale can be used if the algorithm implementation follows a scikit-learn API of fit/predict or fit/transform. You can cast the operator into a Lale operator as follows:\n",
    "\n",
    "```python\n",
    "from lale.operators import make_operator\n",
    "\n",
    "lale_op = make_operator(non_lale_op)\n",
    "```\n",
    "\n",
    "* **I get an error when I instantiate an operator imported from Lale.**\n",
    "\n",
    "    Lale raises errors on invalid hyperparameter values or combinations. This ensures that the operators are used correctly. So don't be surprised if you get any errors when you initialize Lale operators with some hyperparameter values. Chances are that those hyperpameters or combinations of hyperparameters are invalid. If not, find us at **#lale-users** on slack."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
